# Dr.Doctor Scraper

Production-ready web scraping system for collecting structured doctor and hospital data from Pakistani healthcare platforms (Marham, Oladoc) and storing it in MongoDB.

## ğŸš€ Quick Start

```powershell
# 1. Setup
cd dr_doctor_scraper
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt
playwright install

# 2. Configure
copy .env.example .env
# Edit .env and set MONGO_URI

# 3. Run
python run_scraper.py --site marham --threads 4 --limit 10 --test-db
```

## ğŸ“š Documentation

**ğŸ“– [Documentation Index](DOCUMENTATION.md)** - Complete guide to all documentation

### Essential Docs
- **[API Reference](API_REFERENCE.md)** - Complete function and class documentation
- **[Commands Guide](COMMANDS.md)** - All commands, workflows, and usage examples
- **[Changelog](CHANGELOG.md)** - Complete history of all changes and improvements

### Feature Guides
- **[Testing Guide](TESTING.md)** - Testing environment and best practices
- **[Multi-threading Guide](MULTITHREADING.md)** - Parallel processing guide
- **[Step Guide](STEP_GUIDE.md)** - Step-by-step workflow execution

## ğŸ—ï¸ Architecture

### Modular Structure

```
scrapers/
â”œâ”€â”€ base_scraper.py              # Browser management (Playwright)
â”œâ”€â”€ marham_scraper.py            # Single-threaded Marham scraper
â”œâ”€â”€ marham/
â”‚   â”œâ”€â”€ multi_threaded_scraper.py    # Multi-threaded wrapper
â”‚   â”œâ”€â”€ parsers/                     # HTML parsing
â”‚   â”‚   â”œâ”€â”€ hospital_parser.py
â”‚   â”‚   â””â”€â”€ doctor_parser.py
â”‚   â”œâ”€â”€ enrichers/                   # Data enrichment
â”‚   â”‚   â””â”€â”€ profile_enricher.py
â”‚   â”œâ”€â”€ collectors/                  # Data collection
â”‚   â”‚   â””â”€â”€ doctor_collector.py
â”‚   â”œâ”€â”€ handlers/                    # Business logic
â”‚   â”‚   â””â”€â”€ hospital_practice_handler.py
â”‚   â””â”€â”€ mergers/                     # Data merging
â”‚       â””â”€â”€ data_merger.py
â”œâ”€â”€ database/
â”‚   â””â”€â”€ mongo_client.py          # MongoDB operations
â”œâ”€â”€ models/                       # Pydantic data models
â”‚   â”œâ”€â”€ doctor_model.py
â”‚   â””â”€â”€ hospital_model.py
â””â”€â”€ utils/                        # Utility functions
    â”œâ”€â”€ url_parser.py
    â””â”€â”€ parser_helpers.py
```

### Three-Step Workflow

1. **Step 1**: Collect hospitals from listing pages
2. **Step 2**: Enrich hospitals and collect doctor URLs
3. **Step 3**: Process and enrich doctor profiles

Each step is resumable and can be run independently.

## ğŸ¯ Features

- âœ… **Multi-threading**: 4-8x faster with parallel processing
- âœ… **Resumable**: Continue from where you left off
- âœ… **Modular**: Reusable, testable components
- âœ… **Comprehensive**: Captures 50+ data fields per doctor/hospital
- âœ… **Robust**: Error handling, retries, validation
- âœ… **Testable**: Separate test database support
- âœ… **Documented**: Complete API and command reference

## ğŸ“Š Data Captured

### Doctors
- Basic info (name, URL, specialty, platform)
- Qualifications (institute, degree)
- Experience (years, work history)
- Services, diseases, symptoms
- Professional statement, patient stats
- Hospital affiliations with fees/timings
- Private practice information
- Contact details

### Hospitals
- Basic info (name, URL, address, location)
- Founded year, achievements
- Clinical departments, procedures
- Facilities, support services
- Fee ranges, contact numbers
- Doctor lists with details

## ğŸ› ï¸ Technologies

- **Python 3.10+**
- **Playwright** - Browser automation
- **BeautifulSoup** - HTML parsing
- **Pydantic** - Data validation
- **MongoDB** - Data storage
- **Loguru** - Logging

## ğŸ“– Usage Examples

### Basic Scraping

```powershell
# Single-threaded
python run_scraper.py --site marham

# Multi-threaded (4 threads)
python run_scraper.py --site marham --threads 4

# With limit (testing)
python run_scraper.py --site marham --limit 100 --threads 4
```

### Step-by-Step

```powershell
# Step 1: Collect hospitals
python run_scraper.py --site marham --threads 4 --step 1

# Step 2: Enrich hospitals
python run_scraper.py --site marham --threads 4 --step 2

# Step 3: Process doctors
python run_scraper.py --site marham --threads 4 --step 3
```

### Testing

```powershell
# Use test database
python run_scraper.py --site marham --limit 10 --test-db --threads 2

# Validate results
python scripts/validate_data.py --test-db

# Analyze performance
python scripts/analyze_logs.py --limit 10
```

## ğŸ”§ Scripts

- `run_scraper.py` - Main scraper entry point
- `scripts/analyze_logs.py` - Log analysis and statistics
- `scripts/validate_data.py` - Data validation
- `scripts/export_and_clear_db.py` - Database export
- `scripts/log_diagnostics.py` - Detailed log diagnostics

## ğŸ“ Project Status

**Current Phase**: Phase 1 - Scraper Refinement & Testing âœ…

See [Project Roadmap](../README.md#project-roadmap) for full development plan.

## ğŸ¤ Contributing

1. Use test database for development: `--test-db`
2. Run validation after changes: `python scripts/validate_data.py --test-db`
3. Check logs for issues: `python scripts/log_diagnostics.py`
4. Follow modular architecture patterns

## ğŸ“„ License

[Your License Here]

## ğŸ”— Links

- [API Reference](API_REFERENCE.md)
- [Commands Guide](COMMANDS.md)
- [Changelog](CHANGELOG.md)
